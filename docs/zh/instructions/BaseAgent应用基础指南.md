# BaseAgent åº”ç”¨åŸºç¡€æŒ‡å—

## 1. æ¦‚è¿°

`BaseAgent` æ˜¯ Open Pilot Agent çš„æ ¸å¿ƒæŠ½è±¡åŸºç±»ï¼Œæä¾›äº†ç»Ÿä¸€çš„ LLM è°ƒç”¨æ¥å£å’Œé…ç½®ç®¡ç†æœºåˆ¶ã€‚æ‰€æœ‰å…·ä½“çš„ Agent åº”ç”¨éƒ½åº”è¯¥ç»§æ‰¿è‡ªæ­¤ç±»ã€‚

### æ ¸å¿ƒç‰¹æ€§

- **ç»Ÿä¸€çš„ LLM å®¢æˆ·ç«¯ç®¡ç†**: å°è£… LLMClientï¼Œæ”¯æŒå¤šç§æ¨¡å‹
- **è¿è¡Œæ—¶é…ç½®è¦†ç›–**: æ”¯æŒåˆå§‹åŒ–é…ç½®å’Œè¿è¡Œæ—¶é…ç½®çš„çµæ´»ç»„åˆ
- **åŒæ­¥/å¼‚æ­¥è°ƒç”¨**: å®Œæ•´æ”¯æŒåŒæ­¥å’Œå¼‚æ­¥çš„ LLM è°ƒç”¨
- **æµå¼è¾“å‡º**: æ”¯æŒæµå¼å“åº”å¤„ç†
- **æ€è€ƒæ¨¡å¼**: æ”¯æŒ DeepSeek ç­‰æ¨¡å‹çš„æ€è€ƒè¿‡ç¨‹è¾“å‡º

---

## 2. å¿«é€Ÿå¼€å§‹

### 2.1 åˆ›å»ºè‡ªå®šä¹‰ Agent

```python
from base_agent import BaseAgent
from typing import Dict, Any

class MyAgent(BaseAgent):
    """è‡ªå®šä¹‰ Agent ç¤ºä¾‹"""
    
    def __init__(self, **kwargs):
        super().__init__(name="my-agent", **kwargs)
        # åˆå§‹åŒ–è‡ªå®šä¹‰ç»„ä»¶
        self.graph = self._build_graph()
    
    def _build_graph(self):
        """æ„å»º LangGraph å›¾ï¼ˆå¿…é¡»å®ç°ï¼‰"""
        # ç®€å•åœºæ™¯å¯ä»¥è¿”å› None
        return None
    
    def run(self, text: str, **kwargs) -> Dict[str, Any]:
        """æ‰§è¡Œ Agent é€»è¾‘ï¼ˆå¿…é¡»å®ç°ï¼‰"""
        messages = [{"role": "user", "content": text}]
        response = self.call_llm(messages, runtime_config=kwargs)
        return {"output": response.choices[0].message.content}
```

### 2.2 ä½¿ç”¨ Agent

```python
# æ–¹å¼1ï¼šåˆå§‹åŒ–æ—¶æä¾›å®Œæ•´é…ç½®
agent = MyAgent(
    model="deepseek-chat",
    base_url="https://api.deepseek.com/v1",
    api_key="your_api_key"
)
result = agent.run("ä½ å¥½")

# æ–¹å¼2ï¼šè¿è¡Œæ—¶æä¾›é…ç½®ï¼ˆæ¨èç”¨äºå¼€æºåœºæ™¯ï¼‰
agent = MyAgent()  # ä¸æä¾›é…ç½®
result = agent.run(
    "ä½ å¥½",
    model="deepseek-chat",
    base_url="https://api.deepseek.com/v1",
    api_key="your_api_key"
)
```

---

## 3. é…ç½®å‚æ•°è¯´æ˜

### 3.1 åˆå§‹åŒ–å‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `name` | str | "base-agent" | Agent åç§°ï¼Œç”¨äºæ—¥å¿—æ ‡è¯† |
| `model` | str | "deepseek-chat" | æ¨¡å‹åç§° |
| `base_url` | str | "https://api.deepseek.com/v1" | API åŸºç¡€ URL |
| `api_key` | str | None | API å¯†é’¥ |
| `max_tokens` | int | None | æœ€å¤§è¾“å‡º token æ•° |
| `temperature` | float | 0.0 | æ¸©åº¦å‚æ•° (0.0-2.0) |
| `top_p` | float | 1.0 | æ ¸é‡‡æ ·å‚æ•° |
| `timeout` | float | 60.0 | è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ |
| `max_retries` | int | 3 | æœ€å¤§é‡è¯•æ¬¡æ•° |
| `stream` | bool | False | æ˜¯å¦å¯ç”¨æµå¼è¾“å‡º |
| `enable_thinking` | bool | False | æ˜¯å¦å¯ç”¨æ€è€ƒæ¨¡å¼ |

### 3.2 é…ç½®ä¼˜å…ˆçº§

```
è¿è¡Œæ—¶é…ç½® > åˆå§‹åŒ–é…ç½® > ç¯å¢ƒå˜é‡
```

---

## 4. LLM è°ƒç”¨æ–¹æ³•

### 4.1 åŒæ­¥è°ƒç”¨

```python
# éæµå¼
response = agent.call_llm(messages, runtime_config=config)
content = response.choices[0].message.content

# æµå¼
for chunk in agent.stream_llm(messages):
    delta = chunk.choices[0].delta.content
    if delta:
        print(delta, end="")
```

### 4.2 å¼‚æ­¥è°ƒç”¨

```python
# éæµå¼
response = await agent.acall_llm(messages, runtime_config=config)

# æµå¼
async for chunk in agent.astream_llm(messages):
    delta = chunk.choices[0].delta.content
    if delta:
        print(delta, end="")
```

---

## 5. å®Œæ•´ç¤ºä¾‹ï¼šæ–‡æœ¬æ‘˜è¦ Agent

```python
from base_agent import BaseAgent
from typing import Dict, Any, Optional
from langgraph.graph import StateGraph, START, END
from langchain_core.messages import HumanMessage, SystemMessage

class SummarizationAgent(BaseAgent):
    """æ–‡æœ¬æ‘˜è¦ Agent"""
    
    def __init__(self, max_words: int = 200, **kwargs):
        super().__init__(name="summarization-agent", **kwargs)
        self.max_words = max_words
        self.graph = self._build_graph()
    
    def _build_graph(self):
        """æ„å»ºå¤„ç†å›¾"""
        graph = StateGraph(dict)
        
        def summarize_node(state: dict) -> dict:
            """æ‘˜è¦èŠ‚ç‚¹"""
            text = state["text"]
            runtime_config = state.get("runtime_config", {})
            
            messages = [
                {"role": "system", "content": f"è¯·å°†ä»¥ä¸‹æ–‡æœ¬æ‘˜è¦ä¸ºä¸è¶…è¿‡{self.max_words}å­—çš„å†…å®¹"},
                {"role": "user", "content": text}
            ]
            
            response = self.call_llm(messages, runtime_config=runtime_config)
            summary = response.choices[0].message.content
            
            return {**state, "summary": summary}
        
        graph.add_node("summarize", summarize_node)
        graph.add_edge(START, "summarize")
        graph.add_edge("summarize", END)
        
        return graph.compile()
    
    def run(self, text: str, **kwargs) -> Dict[str, Any]:
        """æ‰§è¡Œæ‘˜è¦"""
        result = self.graph.invoke({
            "text": text,
            "runtime_config": kwargs
        })
        return {
            "summary": result["summary"],
            "original_length": len(text),
            "summary_length": len(result["summary"])
        }

# ä½¿ç”¨ç¤ºä¾‹
agent = SummarizationAgent(max_words=100)
result = agent.run(
    "è¿™æ˜¯ä¸€ç¯‡å¾ˆé•¿çš„æ–‡ç« ...",
    model="deepseek-chat",
    base_url="https://api.deepseek.com/v1",
    api_key="your_api_key"
)
print(result["summary"])
```

---

## 6. æ€è€ƒæ¨¡å¼

### 6.1 ä»€ä¹ˆæ˜¯æ€è€ƒæ¨¡å¼

æ€è€ƒæ¨¡å¼ï¼ˆThinking Modeï¼‰å…è®¸æ¨¡å‹è¾“å‡ºå…¶æ¨ç†è¿‡ç¨‹ï¼Œå¸®åŠ©ç”¨æˆ·ç†è§£æ¨¡å‹å¦‚ä½•å¾—å‡ºç»“è®ºã€‚è¿™å¯¹äºéœ€è¦é€æ˜åº¦å’Œå¯è§£é‡Šæ€§çš„åœºæ™¯éå¸¸æœ‰ç”¨ã€‚

### 6.2 é€‚ç”¨åœºæ™¯

| åœºæ™¯ | æ˜¯å¦æ¨è | è¯´æ˜ |
|------|----------|------|
| å¤æ‚æ¨ç†ä»»åŠ¡ | âœ… æ¨è | æ•°å­¦æ¨ç†ã€é€»è¾‘åˆ†æã€ä»£ç è°ƒè¯• |
| é—®ç­”ç³»ç»Ÿ | âœ… æ¨è | éœ€è¦å±•ç¤ºæ¨ç†è¿‡ç¨‹ä»¥å¢å¼ºå¯ä¿¡åº¦ |
| ç®€å•æ–‡æœ¬ç”Ÿæˆ | âŒ ä¸æ¨è | ç¿»è¯‘ã€æ‘˜è¦ç­‰ç®€å•ä»»åŠ¡ä¸éœ€è¦ |
| é«˜å¹¶å‘åœºæ™¯ | âš ï¸ æ…ç”¨ | æ€è€ƒè¿‡ç¨‹ä¼šå¢åŠ  token æ¶ˆè€—å’Œå“åº”æ—¶é—´ |
| åˆ†ç±»ä»»åŠ¡ | âŒ ä¸æ¨è | ç®€å•åˆ†ç±»ä¸éœ€è¦å¤æ‚æ¨ç† |

### 6.3 æ”¯æŒçš„æ¨¡å‹

å½“å‰æ”¯æŒçš„æ¨¡å‹ç±»å‹ï¼ˆé…ç½®æ–‡ä»¶ï¼š`llm_api/thinking_config.py`ï¼‰ï¼š

| æ¨¡å‹ç±»å‹ | æ¨¡å‹ç¤ºä¾‹ | æ€è€ƒå‚æ•° |
|----------|----------|----------|
| **DeepSeek** | `deepseek-reasoner` | æ— éœ€é¢å¤–å‚æ•° |
| **GLM** | `glm-4-plus` | `{"thinking": {"type": "enabled"}}` |
| **Qwen** | `qwen-plus` | `{"enable_thinking": True}` |

> ğŸ“Œ **æ³¨æ„**ï¼šå½“å‰ä»…é€‚é…äº† **OpenAI å…¼å®¹æ ¼å¼** çš„ API æ¥å£ã€‚å¦‚éœ€ä½¿ç”¨å…¶ä»–æ ¼å¼çš„ APIï¼ˆå¦‚ Anthropic åŸç”Ÿæ¥å£ï¼‰ï¼Œéœ€è¦è‡ªè¡Œæ‰©å±• `LLMClient`ã€‚

### 6.4 åŸºæœ¬ä½¿ç”¨

```python
# å¯ç”¨æ€è€ƒæ¨¡å¼
agent = MyAgent(enable_thinking=True)

# æˆ–è¿è¡Œæ—¶å¯ç”¨
result = agent.run(text, enable_thinking=True)

# è·å–æ€è€ƒæ¨¡å¼çŠ¶æ€
status = agent.get_thinking_status()
print(status)  # {"enable_thinking": True, "thinking_params": {...}}

# åŠ¨æ€åˆ‡æ¢
agent.enable_thinking_mode(True)   # å¯ç”¨
agent.enable_thinking_mode(False)  # ç¦ç”¨
```

### 6.5 æ–°å¢/ä¿®æ”¹æ¨¡å‹æ€è€ƒé…ç½®

å¦‚éœ€æ”¯æŒæ–°æ¨¡å‹ï¼Œè¯·ä¿®æ”¹ `llm_api/thinking_config.py`ï¼š

```python
# æ–‡ä»¶: llm_api/thinking_config.py

class ThinkingConfig(object):
    def __init__(self):
        self.model_type_thinking_params = {
            # å·²æœ‰é…ç½®
            "glm": {
                "enable_thinking": {"thinking": {"type": "enabled"}},
                "disable_thinking": {"thinking": {"type": "disabled"}}
            },
            "deepseek": {
                "enable_thinking": {},
                "disable_thinking": {}
            },
            "qwen": {
                "enable_thinking": {"enable_thinking": True},
                "disable_thinking": {"enable_thinking": False}
            },
            # æ–°å¢æ¨¡å‹é…ç½®ç¤ºä¾‹
            "new_model": {
                "enable_thinking": {"custom_param": "value"},
                "disable_thinking": {"custom_param": "disabled"}
            }
        }

    @staticmethod
    def get_model_type(model_name: str) -> str:
        """æ ¹æ®æ¨¡å‹åç§°è·å–æ¨¡å‹ç±»å‹"""
        if model_name.startswith("glm"):
            return "glm"
        elif model_name.startswith("deepseek"):
            return "deepseek"
        elif model_name.startswith("qwen"):
            return "qwen"
        # æ–°å¢æ¨¡å‹ç±»å‹åŒ¹é…
        elif model_name.startswith("new_model"):
            return "new_model"
        return ""
```

**æ­¥éª¤è¯´æ˜**ï¼š
1. åœ¨ `model_type_thinking_params` å­—å…¸ä¸­æ·»åŠ æ–°æ¨¡å‹çš„é…ç½®
2. åœ¨ `get_model_type` æ–¹æ³•ä¸­æ·»åŠ æ¨¡å‹åç§°åŒ¹é…è§„åˆ™

> âš ï¸ **é‡è¦æé†’**ï¼šæ·»åŠ æ–°æ¨¡å‹å‰ï¼Œè¯·å…ˆæŸ¥é˜…å¯¹åº” API çš„å®˜æ–¹æ–‡æ¡£ï¼Œäº†è§£ï¼š
> - è¯¥æ¨¡å‹æ˜¯å¦æ”¯æŒæ€è€ƒæ¨¡å¼
> - å¯ç”¨æ€è€ƒæ¨¡å¼éœ€è¦å“ªäº›ç‰¹å®šå‚æ•°
> - å‚æ•°çš„ä¼ é€’æ–¹å¼ï¼ˆå¦‚ extra_bodyã€headers ç­‰ï¼‰
> - æ˜¯å¦éœ€è¦ä½¿ç”¨ç‰¹å®šçš„æ¨¡å‹ç‰ˆæœ¬ï¼ˆå¦‚ DeepSeek éœ€ä½¿ç”¨ `deepseek-reasoner`ï¼‰

---

## 7. é…ç½®çŠ¶æ€æ£€æŸ¥

```python
# æ£€æŸ¥ LLM æ˜¯å¦å·²é…ç½®
if agent.is_llm_configured:
    print("LLM å·²é…ç½®")

# è·å–è¯¦ç»†é…ç½®çŠ¶æ€
status = agent.get_config_status()
print(status)
# {
#     "llm_configured": True,
#     "init_config": {
#         "model": "deepseek-chat",
#         "api_key": "***",  # å·²è„±æ•
#         ...
#     }
# }
```

---

## 8. æœ€ä½³å®è·µ

### 8.1 ç»§æ‰¿è§„èŒƒ

```python
class MyAgent(BaseAgent):
    def __init__(self, custom_param: str, **kwargs):
        # 1. å…ˆè°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        super().__init__(name="my-agent", **kwargs)
        
        # 2. ä¿å­˜è‡ªå®šä¹‰é…ç½®
        self.custom_param = custom_param
        
        # 3. æœ€åæ„å»ºå›¾
        self.graph = self._build_graph()
    
    def _build_graph(self):
        # å¿…é¡»å®ç°
        pass
    
    def run(self, **kwargs):
        # å¿…é¡»å®ç°
        pass
```

### 8.2 è¿è¡Œæ—¶é…ç½®ä¼ é€’

```python
def run(self, text: str, **kwargs) -> Dict[str, Any]:
    # ä» kwargs æå– LLM é…ç½®
    runtime_config = {
        "model": kwargs.get("model"),
        "base_url": kwargs.get("base_url"),
        "api_key": kwargs.get("api_key"),
        "temperature": kwargs.get("temperature"),
        # ... å…¶ä»–é…ç½®
    }
    # ç§»é™¤ None å€¼
    runtime_config = {k: v for k, v in runtime_config.items() if v is not None}
    
    # ä½¿ç”¨é…ç½®è°ƒç”¨ LLM
    response = self.call_llm(messages, runtime_config=runtime_config)
```

### 8.3 é”™è¯¯å¤„ç†

```python
from typing import Dict, Any

def run(self, **kwargs) -> Dict[str, Any]:
    try:
        response = self.call_llm(messages, runtime_config=kwargs)
        return {"success": True, "output": response.choices[0].message.content}
    except ValueError as e:
        self.logger.error(f"é…ç½®é”™è¯¯: {e}")
        return {"success": False, "error": str(e)}
    except Exception as e:
        self.logger.error(f"è°ƒç”¨å¤±è´¥: {e}")
        return {"success": False, "error": str(e)}
```

---

## 9. ä¸‹ä¸€æ­¥

- é˜…è¯» [BaseAgent è¿›é˜¶æŒ‡å—](./BaseAgentåº”ç”¨è¿›é˜¶æŒ‡å—.md) äº†è§£ LangGraph æ·±åº¦é›†æˆ
- å‚è€ƒ `applications/` ç›®å½•ä¸‹çš„å®Œæ•´å®ç°ç¤ºä¾‹
