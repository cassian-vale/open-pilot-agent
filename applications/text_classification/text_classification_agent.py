import json
import sys
import asyncio
from pathlib import Path
from typing import AsyncGenerator, TypedDict, Annotated, List, Union, Optional, Dict, Any

from pydantic import BaseModel, Field
from langgraph.graph import StateGraph, END
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.runnables import RunnableConfig
from langchain_core.messages.utils import convert_to_openai_messages

dir_name = Path(__file__).resolve().parent.parent.parent
sys.path.append(str(dir_name))

from applications.text_classification.text_classification_prompt import (
    TEXT_CLASSIFICATION_SYSTEM_MESSAGE,
    TEXT_CLASSIFICATION_PROMPT
)
from base_agent import BaseAgent
from llm_api.llm_client_chat_model import LLMClientChatModel
from utils.time_count import timer
from utils.stream_chunk import StreamChunk  # å¼•å…¥æ ‡å‡† StreamChunk


# ===== è¾“å‡ºç»“æ„å®šä¹‰ (å¯¹åº” final_output["output"] çš„å†…å®¹) =====
class TextClassificationOutputContent(BaseModel):
    success: bool = Field(description="åˆ†ç±»æ˜¯å¦æˆåŠŸ")
    predicted_label: str = Field(description="é¢„æµ‹çš„æ ‡ç­¾")
    predicted_token: str = Field(description="é¢„æµ‹çš„æ±‰å­—token")
    all_scores: Dict[str, float] = Field(description="æ‰€æœ‰æ ‡ç­¾çš„å¾—åˆ†")
    label_mapping: Dict[str, str] = Field(description="æ ‡ç­¾åˆ°æ±‰å­—çš„æ˜ å°„å…³ç³»")
    validation_errors: List[str] = Field(default_factory=list, description="éªŒè¯é”™è¯¯ä¿¡æ¯")
    text_length: int = Field(description="è¾“å…¥æ–‡æœ¬é•¿åº¦")
    label_count: int = Field(description="å€™é€‰æ ‡ç­¾æ•°é‡")


# ===== çŠ¶æ€å®šä¹‰ =====
class TextClassificationState(TypedDict):
    messages: Annotated[List[Union[HumanMessage, AIMessage]], "æ¶ˆæ¯å†å²"]
    text: str
    candidate_labels: List[str]
    label_to_token: Dict[str, str]
    token_to_label: Dict[str, str]
    predicted_token: str
    predicted_label: str
    confidence: float
    all_scores: Dict[str, float]
    validation_errors: List[str]
    # æ–°å¢/ä¿®æ”¹å­—æ®µä»¥é€‚é…ç»Ÿä¸€è¾“å‡ºç»“æ„
    final_output: Optional[dict]  # åŒ…å« output, reasoning_content, metadata, confidence
    content: str
    reasoning_content: str
    metadata: Dict[str, Any]


# ===== æ–‡æœ¬åˆ†ç±»Agentä¸»ç±» =====
class TextClassificationAgent(BaseAgent):
    def __init__(
            self,
            name: str = "text-classification-agent",
            # openai client init config
            base_url: str = "https://api.deepseek.com/v1",
            api_key: Optional[str] = None,
            timeout: float = 60.0,
            max_retries: int = 3,
            # openai client run config
            model: str = "deepseek-chat",
            max_tokens: Optional[int] = 1,  # åªè¾“å‡ºä¸€ä¸ªtoken
            temperature: float = 0.1,
            top_p: float = 1.0,
            stream: bool = False,
            enable_thinking: bool = False,
    ):
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        super().__init__(
            name=name,
            model=model,
            base_url=base_url,
            api_key=api_key,
            max_tokens=max_tokens,
            temperature=temperature,
            top_p=top_p,
            timeout=timeout,
            max_retries=max_retries,
            stream=stream,
            enable_thinking=enable_thinking,
        )

        # æ„å»ºå·¥ä½œæµå›¾
        self.graph = self._build_graph()

    def _get_chinese_tokens(self, num_labels: int) -> List[str]:
        """è·å–ç”¨äºæ˜ å°„çš„å­—ç¬¦åˆ—è¡¨"""
        return [chr(num + 97) for num in range(num_labels)]

    def _build_mapping_prompt(self, candidate_labels: List[str]) -> str:
        """æ„å»ºæ ‡ç­¾æ˜ å°„æç¤ºè¯"""
        chinese_tokens = self._get_chinese_tokens(len(candidate_labels))
        label_descriptions = []
        for i, label in enumerate(candidate_labels):
            label_descriptions.append(f"ã€{label}ã€‘å¯¹åº”è¾“å‡ºï¼š{chinese_tokens[i]}")
        
        return "\n".join(label_descriptions)

    def _build_classification_prompt(self, text: str, candidate_labels: List[str]) -> str:
        """æ„å»ºåˆ†ç±»æç¤ºè¯"""
        mapping_prompt = self._build_mapping_prompt(candidate_labels)
        return TEXT_CLASSIFICATION_PROMPT.format(mapping_prompt=mapping_prompt, text=text)

    def _parse_model_output(self, content: str, token_to_label: Dict[str, str], candidate_labels: List[str]) -> Dict[str, Any]:
        """è§£ææ¨¡å‹è¾“å‡º"""
        predicted_token = content.strip()
        if predicted_token:
            predicted_token = predicted_token[0]  # åªå–ç¬¬ä¸€ä¸ªå­—ç¬¦
        
        predicted_label = token_to_label.get(predicted_token, candidate_labels[0])
        
        return {
            "predicted_token": predicted_token,
            "predicted_label": predicted_label
        }

    def _calculate_confidence(self, chat_completion: Dict[str, Any], label_to_token: Dict[str, str]) -> Dict[str, Any]:
        """åŸºäºlogprobsè®¡ç®—ç½®ä¿¡åº¦"""
        all_scores = {}
        confidence = 0.0
        
        try:
            choices = chat_completion.get("choices", [])
            if not choices:
                raise ValueError("choicesä¸ºç©º")
            
            choice = choices[0]
            logprobs = choice.get("logprobs", {})
            
            if logprobs and "content" in logprobs:
                content_logprobs = logprobs["content"]
                
                if content_logprobs and len(content_logprobs) > 0:
                    first_token_logprobs = content_logprobs[0]
                    top_logprobs = first_token_logprobs.get("top_logprobs", [])
                    
                    # è®¡ç®—æ¯ä¸ªå€™é€‰tokençš„æ¦‚ç‡
                    token_probs = {}
                    for token_info in top_logprobs:
                        token = token_info.get("token", "").strip()
                        if token:
                            token = token[0]  # åªå–ç¬¬ä¸€ä¸ªå­—ç¬¦
                        logprob = token_info.get("logprob", 0.0)
                        probability = 2 ** logprob
                        token_probs[token] = probability
                    
                    # è®¡ç®—æ¯ä¸ªæ ‡ç­¾çš„å¾—åˆ†
                    total_prob = 0.0
                    for label, token in label_to_token.items():
                        prob = token_probs.get(token, 0.0)
                        all_scores[label] = prob
                        total_prob += prob
                    
                    # æ ‡å‡†åŒ–å¾—åˆ†å¹¶ä¿ç•™ä¸¤ä½å°æ•°
                    if total_prob > 0:
                        for label in all_scores:
                            normalized_score = all_scores[label] / total_prob
                            all_scores[label] = round(normalized_score, 2)
                    
                    # è·å–é¢„æµ‹æ ‡ç­¾çš„ç½®ä¿¡åº¦
                    predicted_token = choice.get("message", {}).get("content", "").strip()
                    if predicted_token:
                        predicted_token = predicted_token[0]
                    predicted_label = next((label for label, token in label_to_token.items() if token == predicted_token), list(label_to_token.keys())[0])
                    confidence = all_scores.get(predicted_label, 0.0)
                    
                    self.logger.debug(f"ç½®ä¿¡åº¦è®¡ç®—æˆåŠŸ: predicted_label={predicted_label}, confidence={confidence:.2f}")
                else:
                    raise ValueError("content_logprobsä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®")
            else:
                raise ValueError("logprobsæ•°æ®ä¸å­˜åœ¨")
                
        except Exception as e:
            self.logger.warning(f"ç½®ä¿¡åº¦è®¡ç®—å¤±è´¥: {e}")
            # ä½¿ç”¨å‡åŒ€åˆ†å¸ƒä½œä¸ºå›é€€ï¼Œå¹¶ä¿ç•™ä¸¤ä½å°æ•°
            even_score = round(1.0 / len(label_to_token), 2)
            for label in label_to_token.keys():
                all_scores[label] = even_score
            confidence = even_score
            self.logger.info("ä½¿ç”¨å‡åŒ€åˆ†å¸ƒä½œä¸ºç½®ä¿¡åº¦å›é€€æ–¹æ¡ˆ")
        
        return {
            "all_scores": all_scores,
            "confidence": confidence
        }

    def _build_graph(self) -> StateGraph:
        """æ„å»º LangGraph å·¥ä½œæµ"""
        graph = StateGraph(TextClassificationState)

        async def initialize_node(state: TextClassificationState, config: RunnableConfig) -> TextClassificationState:
            """åˆå§‹åŒ–èŠ‚ç‚¹ï¼šå‡†å¤‡æ ‡ç­¾æ˜ å°„"""
            run_config = config.get("configurable", {})
            request_id = run_config.get("request_id")

            with timer(self.logger, f"request_id: {request_id}, åˆå§‹åŒ–æ–‡æœ¬åˆ†ç±»ä»»åŠ¡"):
                self.logger.info(f"request_id: {request_id}, å¼€å§‹æ–‡æœ¬åˆ†ç±», æ–‡æœ¬é•¿åº¦: {len(state['text'])}, æ ‡ç­¾æ•°: {len(state['candidate_labels'])}")
                
                # åˆ›å»ºæ ‡ç­¾åˆ°æ±‰å­—çš„æ˜ å°„
                chinese_tokens = self._get_chinese_tokens(len(state['candidate_labels']))
                label_to_token = {}
                token_to_label = {}
                
                for i, label in enumerate(state['candidate_labels']):
                    token = chinese_tokens[i]
                    
                    label_to_token[label] = token
                    token_to_label[token] = label
                
                self.logger.debug(f"request_id: {request_id}, æ ‡ç­¾æ˜ å°„: {label_to_token}")
                
                return {
                    **state,
                    "label_to_token": label_to_token,
                    "token_to_label": token_to_label
                }

        async def classify_node(state: TextClassificationState, config: RunnableConfig) -> TextClassificationState:
            """åˆ†ç±»èŠ‚ç‚¹ï¼šæ‰§è¡Œæ–‡æœ¬åˆ†ç±»"""
            run_config = config.get("configurable", {})
            request_id = run_config.get("request_id")

            with timer(self.logger, f"request_id: {request_id}, æ‰§è¡Œæ–‡æœ¬åˆ†ç±»"):
                # æ„å»ºæç¤ºè¯
                prompt_text = self._build_classification_prompt(
                    state["text"], 
                    state["candidate_labels"]
                )

                self.logger.info(f"request_id: {request_id}, è°ƒç”¨LLMè¿›è¡Œæ–‡æœ¬åˆ†ç±»")

                messages = [
                    SystemMessage(content=TEXT_CLASSIFICATION_SYSTEM_MESSAGE), 
                    HumanMessage(content=prompt_text)
                ]

                # è°ƒç”¨LLM
                llm_client = self.get_llm_client(run_config)
                chat_model = LLMClientChatModel(llm_client=llm_client)
                try:
                    response = await chat_model.ainvoke(messages, config=config, logprobs=True, top_logprobs=5)

                    chat_completion = response.chat_completion.to_dict()
                    choices = chat_completion.get("choices", [])
                    
                    # åˆå§‹åŒ– metadata
                    output_metadata = {
                        "usage": chat_completion.get("usage", {}),
                        # "messages": []
                    }

                    if len(choices) > 0:
                        content = choices[0].get("message", {}).get("content", "")
                        reasoning_content = choices[0].get("message", {}).get("reasoning_content", "")

                        self.logger.debug(f"request_id: {request_id}, LLMå“åº”: {content}")

                        # è§£æåˆ†ç±»ç»“æœ
                        classification_result = self._parse_model_output(
                            content, 
                            state["token_to_label"], 
                            state["candidate_labels"]
                        )
                        
                        # è®¡ç®—ç½®ä¿¡åº¦
                        confidence_result = self._calculate_confidence(chat_completion, state["label_to_token"])
                        
                        # æ›´æ–°æ¶ˆæ¯å†å²
                        new_messages = state["messages"] + messages + [AIMessage(content=content)]
                        # output_metadata["messages"] = convert_to_openai_messages(new_messages)
                        
                        return {
                            **state,
                            "messages": new_messages,
                            "predicted_token": classification_result["predicted_token"],
                            "predicted_label": classification_result["predicted_label"],
                            "confidence": confidence_result["confidence"],
                            "all_scores": confidence_result["all_scores"],
                            "content": classification_result["predicted_label"],
                            "reasoning_content": reasoning_content,
                            "metadata": output_metadata
                        }
                    else:
                        raise ValueError("LLM apiè¾“å‡ºé”™è¯¯, choicesä¸ºç©º")
                except asyncio.CancelledError:
                    self.logger.warning(f"â›” request_id: {request_id}, ä»»åŠ¡è¢«ä¸­æ–­ï¼Œå·²åœæ­¢ LLM è¯·æ±‚")
                    raise

        def validate_node(state: TextClassificationState, config: RunnableConfig) -> TextClassificationState:
            """éªŒè¯èŠ‚ç‚¹ï¼šéªŒè¯åˆ†ç±»ç»“æœ"""
            run_config = config.get("configurable", {})
            request_id = run_config.get("request_id")

            with timer(self.logger, f"request_id: {request_id}, éªŒè¯åˆ†ç±»ç»“æœ"):
                validation_errors = []
                
                # éªŒè¯é¢„æµ‹çš„tokenæ˜¯å¦åœ¨æ˜ å°„ä¸­
                if state["predicted_token"] not in state["token_to_label"]:
                    validation_errors.append(f"é¢„æµ‹çš„token '{state['predicted_token']}' ä¸åœ¨æœ‰æ•ˆæ˜ å°„ä¸­")
                
                # éªŒè¯ç½®ä¿¡åº¦æ˜¯å¦åˆç†
                if state["confidence"] < 0 or state["confidence"] > 1:
                    validation_errors.append(f"ç½®ä¿¡åº¦ {state['confidence']} è¶…å‡ºåˆç†èŒƒå›´")
                
                # éªŒè¯æ‰€æœ‰æ ‡ç­¾å¾—åˆ†ä¹‹å’Œçº¦ä¸º1
                total_score = sum(state["all_scores"].values())
                if abs(total_score - 1.0) > 0.01 and len(state["all_scores"]) > 0:
                    validation_errors.append(f"æ ‡ç­¾å¾—åˆ†æ€»å’Œ {total_score:.4f} ä¸ç­‰äº1")

                if not validation_errors:
                    self.logger.info(f"request_id: {request_id}, åˆ†ç±»ç»“æœéªŒè¯é€šè¿‡")
                else:
                    self.logger.warning(f"request_id: {request_id}, å‘ç° {len(validation_errors)} ä¸ªéªŒè¯é—®é¢˜")

                state["validation_errors"] = validation_errors
                return state

        def finalize_node(state: TextClassificationState, config: RunnableConfig) -> TextClassificationState:
            """æœ€ç»ˆå¤„ç†èŠ‚ç‚¹ï¼šæ±‡æ€»ç»“æœ"""
            run_config = config.get("configurable", {})
            request_id = run_config.get("request_id")

            with timer(self.logger, f"request_id: {request_id}, ç»“æœæ±‡æ€»"):
                success = len(state["validation_errors"]) == 0
                
                # æ„å»º output å­—å…¸ï¼ˆä¸šåŠ¡æ•°æ®ï¼‰
                output_data = {
                    "predicted_label": state["predicted_label"],
                    # "predicted_token": state["predicted_token"],
                    "all_scores": state["all_scores"],
                    # "label_mapping": state["label_to_token"],
                    # "validation_errors": state["validation_errors"],
                    # "text_length": len(state["text"]),
                    # "label_count": len(state["candidate_labels"])
                }

                # æ„å»ºåŒ…å«å››ä¸ªå›ºå®šå…ƒç´ çš„ final_output
                final_output_structure = {
                    "output": output_data,
                    "content": state["predicted_label"],
                    "reasoning_content": state.get("reasoning_content", ""),
                    "metadata": state.get("metadata", {}),
                    "confidence": state.get("confidence", 0.0)
                }

                status_msg = "æˆåŠŸ" if success else f"æœ‰{len(state['validation_errors'])}ä¸ªè­¦å‘Š"
                self.logger.success(f"request_id: {request_id}, æ–‡æœ¬åˆ†ç±»å®Œæˆ, çŠ¶æ€: {status_msg}, ç½®ä¿¡åº¦: {state['confidence']:.2f}")

                return {
                    **state,
                    "final_output": final_output_structure
                }

        # æ·»åŠ èŠ‚ç‚¹
        graph.add_node("initialize", initialize_node)
        graph.add_node("classify", classify_node)
        graph.add_node("validate", validate_node)
        graph.add_node("finalize", finalize_node)

        # è®¾ç½®å·¥ä½œæµ
        graph.set_entry_point("initialize")
        graph.add_edge("initialize", "classify")
        graph.add_edge("classify", "validate")
        graph.add_edge("validate", "finalize")
        graph.add_edge("finalize", END)

        return graph.compile()

    async def run(self, text: str, candidate_labels: List[str], **kwargs) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ–‡æœ¬åˆ†ç±»æµç¨‹

        :param text: å¾…åˆ†ç±»çš„æ–‡æœ¬
        :param candidate_labels: å€™é€‰æ ‡ç­¾åˆ—è¡¨
        :return: ç»“æ„åŒ–è¾“å‡ºå­—å…¸ {output, reasoning_content, metadata, confidence}
        """
        if not text.strip():
            raise ValueError("æ–‡æœ¬ä¸èƒ½ä¸ºç©º")
        if not candidate_labels:
            raise ValueError("å€™é€‰æ ‡ç­¾åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
        if len(candidate_labels) > 20:
            raise ValueError("å€™é€‰æ ‡ç­¾æœ€å¤šä¸èƒ½è¶…è¿‡20ä¸ª")
        
        request_id = kwargs.get("request_id")

        self.logger.info(f"ğŸ”§ request_id: {request_id}, å¼€å§‹å¤„ç†æ–‡æœ¬åˆ†ç±»è¯·æ±‚, text_length: {len(text)}, labels: {candidate_labels}")

        # æ„å»ºè¿è¡Œæ—¶é…ç½®
        run_config = {k: v for k, v in kwargs.items() if k in self.init_config or k == "request_id"}

        inputs = {
            "messages": [],
            "text": text,
            "candidate_labels": candidate_labels,
            "label_to_token": {},
            "token_to_label": {},
            "predicted_token": "",
            "predicted_label": "",
            "confidence": 0.0,
            "all_scores": {},
            "validation_errors": [],
            "final_output": None,
            "reasoning_content": "",
            "metadata": {}
        }

        with timer(self.logger, f"request_id: {request_id}, å®Œæ•´æ–‡æœ¬åˆ†ç±»æµç¨‹"):
            # ä¼ é€’è¿è¡Œæ—¶é…ç½®
            config = {"configurable": run_config} if run_config else {}
            final_state = await self.graph.ainvoke(inputs, config=config)
            output = final_state.get("final_output", {})
            self.logger.success(f"ğŸ‰ request_id: {request_id}, æ–‡æœ¬åˆ†ç±»å®Œæˆ")

        return output
    

    async def run_stream(self, text: str, candidate_labels: List[str], **kwargs) -> AsyncGenerator[StreamChunk, None]:
        """
        æµå¼æ‰§è¡Œæ–‡æœ¬åˆ†ç±»æµç¨‹

        :param text: å¾…åˆ†ç±»çš„æ–‡æœ¬
        :param candidate_labels: å€™é€‰æ ‡ç­¾åˆ—è¡¨
        :return: StreamChunk æµå¼è¾“å‡ºç”Ÿæˆå™¨
        """
        if not text.strip():
            raise ValueError("æ–‡æœ¬ä¸èƒ½ä¸ºç©º")
        if not candidate_labels:
            raise ValueError("å€™é€‰æ ‡ç­¾åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
        if len(candidate_labels) > 20:
            raise ValueError("å€™é€‰æ ‡ç­¾æœ€å¤šä¸èƒ½è¶…è¿‡20ä¸ª")
        
        request_id = kwargs.get("request_id")

        self.logger.info(f"ğŸ”§ request_id: {request_id}, å¼€å§‹æµå¼å¤„ç†æ–‡æœ¬åˆ†ç±»è¯·æ±‚, text_length: {len(text)}, labels: {candidate_labels}")

        # æ„å»ºè¿è¡Œæ—¶é…ç½®
        run_config = {k: v for k, v in kwargs.items() if k in self.init_config or k == "request_id"}

        # æå‰æ„å»ºæ ‡ç­¾æ˜ å°„ï¼ˆä¸initializeèŠ‚ç‚¹ç›¸åŒçš„é€»è¾‘ï¼‰
        chinese_tokens = self._get_chinese_tokens(len(candidate_labels))
        label_to_token = {}
        token_to_label = {}
        
        for i, label in enumerate(candidate_labels):
            token = chinese_tokens[i]
            
            label_to_token[label] = token
            token_to_label[token] = label

        inputs = {
            "messages": [],
            "text": text,
            "candidate_labels": candidate_labels,
            "label_to_token": label_to_token,
            "token_to_label": token_to_label,
            "predicted_token": "",
            "predicted_label": "",
            "confidence": 0.0,
            "all_scores": {},
            "validation_errors": [],
            "final_output": None,
            "reasoning_content": "",
            "metadata": {}
        }

        # ç”¨äºè·Ÿè¸ªæµå¼è¾“å‡ºçš„çŠ¶æ€
        accumulated_token = ""  # ç´¯ç§¯çš„tokenå­—ç¬¦
        label_emitted = False   # æ ‡è®°æ˜¯å¦å·²ç»è¾“å‡ºäº†æ ‡ç­¾

        with timer(self.logger, f"request_id: {request_id}, å®Œæ•´æµå¼æ–‡æœ¬åˆ†ç±»æµç¨‹"):
            # ä¼ é€’è¿è¡Œæ—¶é…ç½®
            config = {"configurable": run_config} if run_config else {}
            
            async for event in self.graph.astream_events(inputs, config=config):
                event_type = event.get("event", "")
                
                # å¤„ç†LLMæµå¼è¾“å‡º
                if event_type == "on_chat_model_stream":
                    chunk = event.get("data", {}).get("chunk", None)
                    if chunk and hasattr(chunk, "chat_completion_chunk") and chunk.chat_completion_chunk:
                        chat_completion_chunk = chunk.chat_completion_chunk.to_dict()
                        choices = chat_completion_chunk.get("choices", [])
                        if choices:
                            delta = choices[0].get("delta", {})
                            content = delta.get("content", "")
                            reasoning_content = delta.get("reasoning_content", "")
                            
                            # è¾“å‡ºæ€è€ƒå†…å®¹
                            if reasoning_content:
                                yield StreamChunk(
                                    type="thinking",
                                    content=reasoning_content
                                )
                            
                            # å¤„ç†åˆ†ç±»tokenè¾“å‡º - åªå–ç¬¬ä¸€ä¸ªæœ‰æ•ˆå­—ç¬¦
                            if content and not label_emitted:
                                # ç´¯ç§¯tokenå­—ç¬¦ï¼Œä½†åªå–ç¬¬ä¸€ä¸ªéç©ºå­—ç¬¦
                                if content.strip() and not accumulated_token:
                                    accumulated_token = content.strip()[0]  # åªå–ç¬¬ä¸€ä¸ªå­—ç¬¦
                                    
                                    # å°è¯•æ˜ å°„åˆ°æ ‡ç­¾
                                    predicted_label = token_to_label.get(accumulated_token, candidate_labels[0])
                                    
                                    # è¾“å‡ºæ˜ å°„åçš„æ ‡ç­¾
                                    yield StreamChunk(
                                        type="content",
                                        content=predicted_label  # ç›´æ¥è¾“å‡ºæ ‡ç­¾è€Œä¸æ˜¯token
                                    )
                                    
                                    label_emitted = True
                                    self.logger.debug(f"request_id: {request_id}, æµå¼æ˜ å°„: token='{accumulated_token}' -> label='{predicted_label}'")
                
                # å¤„ç†èŠ‚ç‚¹å¼€å§‹äº‹ä»¶
                elif event_type == "on_chain_start":
                    name = event.get("name", "")
                    if name == "initialize":
                        yield StreamChunk(
                            type="processing",
                            content="åˆå§‹åŒ–..."
                        )
                    elif name == "classify":
                        yield StreamChunk(
                            type="processing",
                            content="åˆ†æï¼šæ­£åœ¨æ‰§è¡Œåˆ†ç±»æ¨æ–­..."
                        )
                    elif name == "validate":
                        yield StreamChunk(
                            type="processing", 
                            content="éªŒè¯ï¼šæ£€æŸ¥åˆ†ç±»ç½®ä¿¡åº¦..."
                        )
                    elif name == "finalize":
                        yield StreamChunk(
                            type="processing",
                            content="æ±‡æ€»ï¼šæ­£åœ¨ç”Ÿæˆæœ€ç»ˆç»“æœ..."
                        )
                
                # å¤„ç†èŠ‚ç‚¹ç»“æŸäº‹ä»¶
                elif event_type == "on_chain_end":
                    name = event.get("name", "")
                    # å¤„ç†å›¾ç»“æŸäº‹ä»¶, è¾“å‡ºæœ€ç»ˆç»“æœ
                    if name == "LangGraph":
                        output = event.get("data", {}).get("output", {})
                        final_output_data = output.get("final_output", {})
                        
                        # ç¡®ä¿æ˜¯å®Œæ•´çš„ final_output ç»“æ„
                        if final_output_data:
                            yield StreamChunk(
                                type="final",
                                content="",
                                metadata=final_output_data
                            )

            self.logger.success(f"ğŸ‰ request_id: {request_id}, æµå¼æ–‡æœ¬åˆ†ç±»å®Œæˆ")


# ===== ä½¿ç”¨ç¤ºä¾‹ =====
async def main():
    """ä½¿ç”¨ç¤ºä¾‹"""
    
    # åˆå§‹åŒ–Agent
    agent = TextClassificationAgent(
        name="test-classification-agent",
        base_url="https://api.deepseek.com/v1",
        api_key="YOUR_API_KEY",  # æ›¿æ¢ä¸ºå®é™…APIå¯†é’¥
        temperature=0.1
    )
    
    # æµ‹è¯•ç”¨ä¾‹
    test_text = "è¿™å®¶é¤å…çš„é£Ÿç‰©éå¸¸ç¾å‘³, æœåŠ¡ä¹Ÿå¾ˆå‘¨åˆ°, å¼ºçƒˆæ¨èï¼"
    test_labels = ["æ­£é¢è¯„ä»·", "è´Ÿé¢è¯„ä»·", "ä¸­æ€§è¯„ä»·"]
    
    print(f"\n=== æµ‹è¯•æ–‡æœ¬åˆ†ç±» ===")
    print(f"æ–‡æœ¬: {test_text}")
    print(f"æ ‡ç­¾: {test_labels}")
    
    # ç¤ºä¾‹1: éæµå¼è°ƒç”¨
    print("\n--- 1. éæµå¼è°ƒç”¨ ---")
    result = await agent.run(
        text=test_text,
        candidate_labels=test_labels,
        request_id="test-classify-001"
    )
    
    output_content = result.get("output", {})
    confidence = result.get("confidence", 0.0)
    print(f"âœ… åˆ†ç±»ç»“æœ: {output_content.get('predicted_label')}")
    print(f"ğŸ“Š ç½®ä¿¡åº¦: {confidence:.4f}")
    print(f"ğŸ“ å®Œæ•´è¾“å‡ºkeys: {list(result.keys())}") # éªŒè¯æ˜¯å¦åªæœ‰4ä¸ªkey

    # ç¤ºä¾‹2: æµå¼è°ƒç”¨
    print("\n--- 2. æµå¼è°ƒç”¨ ---")
    async for chunk in agent.run_stream(
        text=test_text,
        candidate_labels=test_labels,
        request_id="test-classify-002"
    ):
        if chunk.type == "thinking":
            print(f"ğŸ¤” {chunk.content}")
        elif chunk.type == "processing":
            print(f"ğŸ”„ {chunk.content}")
        elif chunk.type == "content":
            print(f"ğŸ“ ç”Ÿæˆå†…å®¹: {chunk.content}")
        elif chunk.type == "final":
            final_data = chunk.metadata
            output = final_data.get("output", {})
            print(f"\nâœ… æµå¼å®Œæˆ. æœ€ç»ˆæ ‡ç­¾: {output.get('predicted_label')}")
            print(f"ğŸ“ˆ æ‰€æœ‰å¾—åˆ†: {output.get('all_scores')}")

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())