# schema_generation_app.py
import asyncio
import os
import sys
import json
import traceback
from pathlib import Path
from typing import Optional, Dict, Any, Union
from contextlib import asynccontextmanager

import uvicorn
from loguru import logger
from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
dir_name = Path(__file__).resolve().parent.parent.parent
sys.path.append(str(dir_name))


from applications.schema_generation.schema_generation_agent import SchemaGenerationAgent
from utils.log_util import logger_pool
from utils.http_factory import GlobalHTTPFactory


# ===== è¯·æ±‚/å“åº”æ¨¡å‹ =====
class SchemaGenerationRequest(BaseModel):
    request_id: str = Field(..., description="è¯·æ±‚IDï¼Œç”¨äºè¿½è¸?)
    user_requirements: str = Field(..., description="ç”¨æˆ·å¯¹Schemaçš„éœ€æ±‚æè¿?)
    domain_context: Optional[str] = Field(default=None, description="é¢†åŸŸä¸Šä¸‹æ–‡ä¿¡æ?)
    
    # --- å¿…å¡«å‚æ•° (ä¿®æ”¹ç‚? ---
    model: str = Field(..., description="æ¨¡å‹åç§° (å¿…å¡«)")
    base_url: str = Field(..., description="APIåŸºç¡€URL (å¿…å¡«)")
    api_key: str = Field(..., description="APIå¯†é’¥ (å¿…å¡«)")
    # -----------------------

    # æµå¼æ§åˆ¶å‚æ•°
    stream: bool = Field(default=False, description="æ˜¯å¦å¯ç”¨æµå¼è¾“å‡º")

    # LLM é…ç½®å‚æ•°
    max_tokens: Optional[int] = Field(default=None, description="æœ€å¤§tokenæ•?)
    temperature: float = Field(default=0.1, description="æ¸©åº¦å‚æ•°")
    top_p: float = Field(default=1.0, description="Top-på‚æ•°")
    timeout: float = Field(default=60.0, description="è¶…æ—¶æ—¶é—´")
    max_retries: int = Field(default=3, description="æœ€å¤§é‡è¯•æ¬¡æ•?)
    enable_thinking: bool = Field(default=False, description="æ˜¯å¦å¯ç”¨æ€è€ƒè¿‡ç¨?)


class SchemaGenerationResponse(BaseModel):
    output: Dict[str, Any]
    content: str = Field(default="", description="æ¨¡å‹æœ€ç»ˆè¾“å‡?)
    reasoning_content: str = Field(default="", description="æ€è€ƒè¿‡ç¨?)
    metadata: Dict[str, Any] = Field(default=None, description="å…ƒæ•°æ?)
    confidence: float = Field(default=1.0, description="æ•´ä½“ç½®ä¿¡åº?, ge=0, le=1)


# ===== ç”Ÿå‘½å‘¨æœŸç®¡ç† =====
agent_instance: Optional[SchemaGenerationAgent] = None
app_logger = logger

@asynccontextmanager
async def lifespan(app: FastAPI):
    global agent_instance
    print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ?SchemaGenerationAgent...")
    try:
        # ä½¿ç”¨é»˜è®¤é…ç½®åˆå§‹åŒ?
        app_name = "schema_generation"
        logger_pool.set_logger(
            name=app_name,
            log_level=os.getenv("SG_LOG_LEVEL", "INFO"),
            log_dir=os.getenv("SG_LOG_DIR", ""),
            retention=os.getenv("SG_LOG_RETENTION", ""),
            rotation=os.getenv("SG_LOG_ROTATION", ""),
        )
        app_logger = logger_pool.get_logger(app_name)

        agent_instance = SchemaGenerationAgent(
            name="schemaGeneration",
            model=os.getenv("SG_MODEL", "deepseek-chat"),
            base_url=os.getenv("SG_BASE_URL", "https://api.deepseek.com/v1"),
            api_key=os.getenv("SG_API_KEY", ""),
            timeout=float(os.getenv("SG_TIMEOUT", "60.0")),
            max_retries=int(os.getenv("SG_MAX_RETRIES", "3")),
            max_tokens=int(os.getenv("SG_MAX_TOKENS", "0")) or None,
            temperature=float(os.getenv("SG_TEMPERATURE", "0.1")),
            top_p=float(os.getenv("SG_TOP_P", "1.0")),
            stream=bool(os.getenv("SG_STREAM", "False")),
            enable_thinking=bool(os.getenv("SG_ENABLE_THINKING", "False")),
        )
        app_logger.info("âœ?SchemaGenerationAgent åˆå§‹åŒ–å®Œæˆ?)
    except Exception as e:
        print(f"â?åˆå§‹åŒ–å¤±è´? {e}")
        raise

    yield

    # å…³é—­æ—¶æ¸…ç?
    print("ğŸ§¹ æ¸…ç†èµ„æº...")
    await GlobalHTTPFactory.close()
    agent_instance = None


# ===== FastAPI App =====
app = FastAPI(
    title="Schemaç”ŸæˆæœåŠ¡ API",
    description="åŸºäº LangGraph + LLM çš„Schemaç”ŸæˆæœåŠ¡ï¼Œæ ¹æ®è‡ªç„¶è¯­è¨€éœ€æ±‚è‡ªåŠ¨ç”ŸæˆJSON Schema",
    version="1.0.0",
    lifespan=lifespan,
    root_path="/schema_generation/v1"
)

# æ·»åŠ  CORS ä¸­é—´ä»?
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ===== å¥åº·æ£€æŸ¥æ¥å?=====
@app.get("/health", summary="å¥åº·æ£€æŸ?)
async def health_check():
    if agent_instance is None:
        raise HTTPException(status_code=503, detail="Agent æœªåˆå§‹åŒ–")
    return {"status": "OK", "agent": "initialized"}


# ===== ç»Ÿä¸€Schemaç”Ÿæˆæ¥å£ (åˆå¹¶æµå¼ä¸éæµå¼) =====
@app.post("/chat", response_model=Union[SchemaGenerationResponse, str], summary="Schemaç”Ÿæˆï¼ˆè‡ªåŠ¨è¯†åˆ«æµå¼?éæµå¼ï¼‰")
async def chat_endpoint(request_body: SchemaGenerationRequest, raw_request: Request):
    """
    ç»Ÿä¸€Schemaç”Ÿæˆæ¥å£ï¼?
    - å¦‚æœ request_body.stream == True: è¿”å› SSE æµ?(text/event-stream)
    - å¦‚æœ request_body.stream == False: è¿”å› JSON (application/json)
    å‡æ”¯æŒå®¢æˆ·ç«¯æ–­å¼€è¿æ¥æ—¶è‡ªåŠ¨ä¸­æ–­åç«¯æ¨ç†ã€?
    
    æ ¹æ®ç”¨æˆ·æä¾›çš„è‡ªç„¶è¯­è¨€éœ€æ±‚æè¿°ï¼Œè‡ªåŠ¨ç”Ÿæˆç¬¦åˆè§„èŒƒçš„JSON Schemaã€?
    """
    if agent_instance is None:
        raise HTTPException(status_code=503, detail="æœåŠ¡æœªå°±ç»ªï¼Œè¯·ç¨åå†è¯?)

    # æ„å»ºè¿è¡Œæ—¶å‚æ•?
    # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬å¼ºåˆ?enable stream=True ä¼ ç»™åº•å±‚ Agentï¼?
    # è¿™æ ·åº•å±‚ä¼šæŒ‰ Token ç”Ÿæˆï¼Œæˆ‘ä»¬æ‰èƒ½åœ¨éæµå¼æ¨¡å¼ä¸‹ä¹Ÿè¿›è¡Œç»†ç²’åº¦çš„ä¸­æ–­æ£€æµ‹ã€?
    run_config = {
        "request_id": request_body.request_id,
        # å¿…å¡«é¡¹ï¼šä½¿ç”¨è¯·æ±‚ä¸­çš„å‚æ•°
        "model": request_body.model,
        "base_url": request_body.base_url,
        "api_key": request_body.api_key,

        # å¯é€‰é¡¹
        "max_tokens": request_body.max_tokens,
        "temperature": request_body.temperature,
        "top_p": request_body.top_p,
        "timeout": request_body.timeout,
        "max_retries": request_body.max_retries,
        "stream": True,  # â˜?å¼ºåˆ¶å¼€å¯åº•å±‚æµå¼ï¼Œä»¥ä¾¿äºç»†ç²’åº¦æ§åˆ¶ä¸­æ–­
        "enable_thinking": request_body.enable_thinking,
    }
    
    # è¿‡æ»¤æ‰Noneå€?
    run_config = {k: v for k, v in run_config.items() if v is not None}

    # === åˆ†æ”¯ 1ï¼šæµå¼å“åº?(SSE) ===
    if request_body.stream:
        async def generate_sse():
            try:
                # 1. å‘é€å¼€å§‹äº‹ä»?
                start_event = {
                    "type": "start",
                    "content": "",
                    "metadata": {"request_id": request_body.request_id, "status": "started"}
                }
                yield f"data: {json.dumps(start_event, ensure_ascii=False)}\n\n"
                
                # 2. å¾ªç¯ç”Ÿæˆå†…å®¹
                async for chunk in agent_instance.run_stream(
                    user_requirements=request_body.user_requirements,
                    domain_context=request_body.domain_context,
                    **run_config
                ):
                    # â˜?å®æ—¶æ£€æµ‹ä¸­æ–?
                    if await raw_request.is_disconnected():
                        app_logger.warning(f"ğŸš« request_id: {request_body.request_id} [Stream] å®¢æˆ·ç«¯æ–­å¼€è¿æ¥")
                        break
                    
                    yield f"data: {chunk.model_dump_json()}\n\n"
                    
                # 3. å‘é€ç»“æŸäº‹ä»?
                end_event = {
                    "type": "end", 
                    "content": "",
                    "metadata": {"request_id": request_body.request_id, "status": "completed"}
                }
                yield f"data: {json.dumps(end_event, ensure_ascii=False)}\n\n"
                
            except asyncio.CancelledError:
                app_logger.warning(f"ğŸš« request_id: {request_body.request_id} [Stream] ä»»åŠ¡è¢«ç³»ç»Ÿå–æ¶?)
                raise  # é‡æ–°æŠ›å‡ºä»¥ç¡®ä¿èµ„æºæ¸…ç?
            except Exception as e:
                app_logger.error(f"æµå¼å¤„ç†é”™è¯¯: {traceback.format_exc()}")
                error_event = {"type": "error", "content": f"å¤„ç†é”™è¯¯: {str(e)}"}
                yield f"data: {json.dumps(error_event, ensure_ascii=False)}\n\n"

        return StreamingResponse(
            generate_sse(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no",
            }
        )

    # === åˆ†æ”¯ 2ï¼šéæµå¼å“åº” (JSON) ===
    else:
        try:
            final_response = dict()
            
            # åŒæ ·è°ƒç”¨ run_streamï¼Œä½†åœ¨åç«¯æ¶ˆè´¹æ‰ä¸­é—´è¿‡ç¨‹
            async for chunk in agent_instance.run_stream(
                user_requirements=request_body.user_requirements,
                domain_context=request_body.domain_context,
                **run_config
            ):
                # â˜?å®æ—¶æ£€æµ‹ä¸­æ–­ï¼šå³ä½¿æ˜¯éæµå¼ï¼Œä¹Ÿèƒ½åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­è¢«ææ–­
                if await raw_request.is_disconnected():
                    app_logger.warning(f"ğŸš« request_id: {request_body.request_id} [Non-Stream] å®¢æˆ·ç«¯æ–­å¼€è¿æ¥")
                    # è¿™é‡ŒæŠ›å‡ºå¼‚å¸¸ä¼šåœæ­?run_stream çš„æ‰§è¡?
                    raise HTTPException(status_code=499, detail="Client Closed Request")
                
                # åªæ•è?final ç±»å‹çš„å—
                if chunk.type == "final":
                    # metadata ä¸­åŒ…å«äº†å®Œæ•´çš?SchemaGenerationResponse æ‰€éœ€å­—æ®µ
                    final_response = chunk.metadata
            
            return SchemaGenerationResponse(**final_response)

        except HTTPException:
            raise
        except asyncio.CancelledError:
            app_logger.warning(f"ğŸš« request_id: {request_body.request_id} [Non-Stream] ä»»åŠ¡è¢«å–æ¶?)
            raise HTTPException(status_code=499, detail="Request Cancelled")
        except Exception as e:
            app_logger.error(f"éæµå¼å¤„ç†é”™è¯? {traceback.format_exc()}")
            raise HTTPException(status_code=500, detail=f"å†…éƒ¨é”™è¯¯: {str(e)}")


# ===== å¯åŠ¨å‘½ä»¤ =====
if __name__ == "__main__":
    uvicorn.run(
        "schema_generation_app:app", 
        host="0.0.0.0", 
        port=8104,  # ä½¿ç”¨æ–°çš„ç«¯å£ï¼Œä¾‹å¦?004
        log_level="info"
    )